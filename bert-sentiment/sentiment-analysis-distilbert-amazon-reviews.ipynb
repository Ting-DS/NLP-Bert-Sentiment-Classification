{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Sentiment Analysis of Amazon Reviews","metadata":{}},{"cell_type":"markdown","source":"![](https://www.topbots.com/wp-content/uploads/2020/01/cover_sentiment_analysis_BERT_1600px_web-1280x640.jpg)\n\nHello Everyone!\n\nIn this notebook, I’ll work with data from Amazon Review, which consists of 360000 reviews. There’re only positive and negative sentences.\n\nSteps:\n* EDA\n* Baseline Logistic Regression(Tf-Idf)\n* DistilBert\n* [DistilBert Inference Optimization](https://www.kaggle.com/alexalex02/nlp-transformers-inference-optimization)","metadata":{}},{"cell_type":"markdown","source":"## Importing libraries and reading data","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nimport warnings\nimport seaborn as sns\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, f1_score, confusion_matrix\nfrom sklearn.model_selection import train_test_split\nimport joblib\nimport eli5","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_val = pd.read_csv('../input/amazontrainreviews/train.csv', index_col=0)\ntrain_val.reset_index(drop=True, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"code","source":"print(train_val.info())\ndisplay(train_val.head())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We have 0 Null value and now let's look at target distribution","metadata":{}},{"cell_type":"code","source":"sns.countplot(train_val['labels']);\nplt.title('Labels distribution');","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let’s count number of words and see it distribution","metadata":{}},{"cell_type":"code","source":"train_val['len'] = train_val['sentences'].apply(lambda x: len(x.split()))\nsns.distplot(train_val['len']);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we’ll divide it by sentiment and calculate average values","metadata":{}},{"cell_type":"code","source":"neg_mean_len = train_val.groupby('labels')['len'].mean().values[0]\npos_mean_len = train_val.groupby('labels')['len'].mean().values[1]\n\nprint(f\"Negative mean length: {neg_mean_len:.2f}\")\nprint(f\"Positive mean length: {pos_mean_len:.2f}\")\nprint(f\"Mean Difference: {neg_mean_len-pos_mean_len:.2f}\")\nax = sns.catplot(x='labels', y='len', data=train_val, kind='box')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that negative sentences are longer on average. To say how significant this difference, we use permutation testing and calculate p-value.\n\nFirst, we define a function to generate a permutation sample from two arrays. Then, we generate permutation replicates, which are a single statistic computed from permutation sample. Last, we compute the probability of getting at least 5.91 difference in mean under the hypothesis that the distributions of words are identical.","metadata":{}},{"cell_type":"code","source":"neg_array = train_val[train_val['labels']==0]['len'].values\npos_array = train_val[train_val['labels']==1]['len'].values\nmean_diff = neg_mean_len - pos_mean_len","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def permutation_sample(data1, data2):\n    # Permute the concatenated array: permuted_data\n    data = np.concatenate((data1,data2))\n    permuted_data = np.random.permutation(data)\n\n    # Split the permuted array into two: perm_sample_1, perm_sample_2\n    perm_sample_1 = permuted_data[:len(data1)]\n    perm_sample_2 = permuted_data[len(data1):]\n\n    return perm_sample_1, perm_sample_2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def draw_perm_reps(data_1, data_2, size=1):\n\n    perm_replicates = np.empty(size)\n\n    for i in range(size):\n        # Generate permutation sample\n        perm_sample_1, perm_sample_2 = permutation_sample(data_1, data_2)\n\n        # Compute the test statistic\n        perm_replicates[i] = np.mean(perm_sample_1) - np.mean(perm_sample_2)\n\n    return perm_replicates","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"perm_replicates = draw_perm_reps(neg_array, pos_array,\n                                 size=10000)\n\n# Compute p-value: p\np = np.sum(perm_replicates >= mean_diff) / len(perm_replicates)\n\nprint(f'p-value = {p}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The p-value tells us that the null hypothesis is false.","metadata":{}},{"cell_type":"markdown","source":"# Baseline - LogReg (Tf-Idf)","metadata":{}},{"cell_type":"markdown","source":"Our baseline will be Logistic Regression with Tf-Idf. First, we define a function for prediction, which calculates accuracy, f1_score, confusion matrix and saves our model.","metadata":{}},{"cell_type":"code","source":"def prediction(model, X_train, y_train, X_valid, y_valid):\n    model.fit(X_train, y_train)\n    pred = model.predict(X_valid)\n    acc = accuracy_score(y_valid, pred)\n    f1 = f1_score(y_valid, pred)\n    conf = confusion_matrix(y_valid, pred)\n    joblib.dump(model, f\"model_acc_{acc:.5f}.pkl\")\n    return model, acc, f1, conf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Extracting unigrams, bigrams and trigrams, also removing stopwords.","metadata":{}},{"cell_type":"code","source":"transformer = TfidfVectorizer(stop_words='english', ngram_range=(1, 3), \n                              lowercase=True, max_features=100000)\nX = transformer.fit_transform(train_val['sentences'])\ny = train_val.labels","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, \n                                                      random_state=42, stratify=y)\nmodel = LogisticRegression(C=1, random_state=42, n_jobs=-1)\nfit_model, acc, f1, conf = prediction(model, X_train, y_train, X_valid, y_valid)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Accuracy: {acc:.5f}\")\nprint(f\"F1_Score: {f1:.5f}\")\nprint(f\"Confusion Matrix: {conf}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Interpreting model weights with ELI5.","metadata":{}},{"cell_type":"code","source":"eli5.show_weights(estimator=fit_model, \n                  feature_names= list(transformer.get_feature_names()),\n                    top=(20,20))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# DistilBert","metadata":{}},{"cell_type":"markdown","source":"Here we'll use DistilBert from [transformers](https://huggingface.co/transformers/index.html). And [catalyst](https://github.com/catalyst-team/catalyst) for running experiment.\n\nFirst, we install torch nightly for Mixed-precision training.","metadata":{}},{"cell_type":"code","source":"!pip install --pre torch==1.7.0.dev20200701+cu101 torchvision==0.8.0.dev20200701+cu101 -f https://download.pytorch.org/whl/nightly/cu101/torch_nightly.html\nimport torch\ntorch.__version__","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nos.environ['WANDB_SILENT'] = 'True'\nos.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n\nfrom typing import Mapping, List\nfrom tqdm import tqdm\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\n\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn.functional as F\n\nfrom transformers import AutoConfig, AutoTokenizer, AutoModel\n\nfrom catalyst.dl import SupervisedRunner\nfrom catalyst.dl.callbacks import AccuracyCallback, OptimizerCallback, CheckpointCallback, WandbLogger\nfrom catalyst.utils import set_global_seed, prepare_cudnn\nfrom catalyst.contrib.nn import RAdam, Lookahead, OneCycleLRWithWarmup\nimport wandb","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Config setup","metadata":{}},{"cell_type":"code","source":"MODEL_NAME = 'distilbert-base-uncased'\nLOG_DIR = \"./amazon\" \nNUM_EPOCHS = 2 \nLEARNING_RATE = 5e-5\nMAX_SEQ_LENGTH = 512\nBATCH_SIZE = 32\nWEIGHT_DECAY = 1e-3\nACCUMULATION_STEPS = 3\nSEED = 42\nFP_16 = dict(opt_level=\"O1\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For reproducibility","metadata":{}},{"cell_type":"code","source":"set_global_seed(SEED)\nprepare_cudnn(deterministic=True, benchmark=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We'll create dataset. Instantiate tokenizer. Then, we convert tokens to integers, add special tokens, use padding to max_length. Return `'input_ids', 'attention_mask', 'targets'`","metadata":{}},{"cell_type":"code","source":"class ReviewDataset(Dataset):\n\n    \n    def __init__(self,\n                 sentences: List[str],\n                 labels: List[str] = None,\n                 max_seq_length: int = MAX_SEQ_LENGTH,\n                 model_name: str = 'distilbert-base-uncased'):\n\n        self.sentences = sentences\n        self.labels = labels\n        self.max_seq_length = max_seq_length\n\n        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n\n        \n    def __len__(self):\n\n        return len(self.sentences)\n\n    \n    def __getitem__(self, index) -> Mapping[str, torch.Tensor]:\n\n        sentence = self.sentences[index]\n        encoded = self.tokenizer.encode_plus(sentence, add_special_tokens=True, \n                                        pad_to_max_length=True, max_length=self.max_seq_length, \n                                        return_tensors=\"pt\",)\n        \n        output = {\n            'input_ids': encoded['input_ids'],\n            'attention_mask': encoded['attention_mask']\n        }\n        \n        output['targets'] = torch.tensor(self.labels[index], dtype=torch.long)\n        \n        return output","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Making train_test_split, defining datasets and loaders","metadata":{}},{"cell_type":"code","source":"df_train, df_valid = train_test_split(\n            train_val,\n            test_size=0.2,\n            random_state=42,\n            stratify = train_val.labels.values\n        )\nprint(df_train.shape, df_valid.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = ReviewDataset(\n    sentences=df_train['sentences'].values.tolist(),\n    labels=df_train['labels'].values,\n    max_seq_length=MAX_SEQ_LENGTH,\n    model_name=MODEL_NAME\n)\n\nvalid_dataset = ReviewDataset(\n    sentences=df_valid['sentences'].values.tolist(),\n    labels=df_valid['labels'].values,\n    max_seq_length=MAX_SEQ_LENGTH,\n    model_name=MODEL_NAME\n)","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_val_loaders = {\n    \"train\": DataLoader(dataset=train_dataset,\n                        batch_size=BATCH_SIZE, \n                        shuffle=True, num_workers=2, pin_memory=True),\n    \"valid\": DataLoader(dataset=valid_dataset,\n                        batch_size=BATCH_SIZE, \n                        shuffle=False, num_workers=2, pin_memory=True)    \n}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Review and model input","metadata":{}},{"cell_type":"code","source":"print(df_valid.sentences.values[50])\nvalid_dataset[50]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Initialize pre-trained model. From config we'll use dimensionality of the encoder layers and the pooler layer = 768. And dropout probabilities = 0.2. Then, we'll compute logits for the input sequence.","metadata":{}},{"cell_type":"code","source":"class DistilBert(nn.Module):\n\n    def __init__(self, pretrained_model_name: str = MODEL_NAME, num_classes: int = 2):\n\n        super().__init__()\n\n        config = AutoConfig.from_pretrained(\n             pretrained_model_name)\n\n        self.distilbert = AutoModel.from_pretrained(pretrained_model_name,\n                                                    config=config)\n        self.pre_classifier = nn.Linear(config.dim, config.dim)\n        self.classifier = nn.Linear(config.dim, num_classes)\n        self.dropout = nn.Dropout(config.seq_classif_dropout)\n\n    def forward(self, input_ids, attention_mask=None, head_mask=None):\n\n        assert attention_mask is not None, \"attention mask is none\"\n        distilbert_output = self.distilbert(input_ids=input_ids,\n                                            attention_mask=attention_mask,\n                                            head_mask=head_mask)\n        hidden_state = distilbert_output[0]  # [BATCH_SIZE=32, MAX_SEQ_LENGTH = 512, DIM = 768]\n        pooled_output = hidden_state[:, 0]  # [32, 768]\n        pooled_output = self.pre_classifier(pooled_output)  # [32, 768]\n        pooled_output = F.relu(pooled_output)  # [32, 768]\n        pooled_output = self.dropout(pooled_output)  # [32, 768]\n        logits = self.classifier(pooled_output)  # [32, 2]\n\n        return logits","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = DistilBert()","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Training setup:\n\n1. We'll apply weight decay for all parameters except 'bias' and 'LayerNorm'\n1. Lookahead optimizer(improves the learning stability and lowers the variance of its inner optimizer)\n1. OneCycleLRWithWarmup with 0 warmup steps, cosine annealing from 5e-5 to 1e-8.\n1. Gradient accumulation for large batch training.","metadata":{}},{"cell_type":"code","source":"param_optim = list(model.named_parameters())\nno_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\n\nbase_optimizer = RAdam([\n    {'params': [p for n,p in param_optim if not any(nd in n for nd in no_decay)],\n     'weight_decay': WEIGHT_DECAY}, \n    {'params': [p for n,p in param_optim if any(nd in n for nd in no_decay)],\n     'weight_decay': 0.0}\n])\noptimizer = Lookahead(base_optimizer)\nscheduler = OneCycleLRWithWarmup(\n    optimizer, \n    num_steps=NUM_EPOCHS, \n    lr_range=(LEARNING_RATE, 1e-8),\n    init_lr=LEARNING_RATE,\n    warmup_steps=0,\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"runner = SupervisedRunner(\n    input_key=(\n        \"input_ids\",\n        \"attention_mask\"\n    )\n)\n# model training\nrunner.train(\n    model=model,\n    criterion=criterion,\n    optimizer=optimizer,\n    scheduler=scheduler,\n    loaders=train_val_loaders,\n    callbacks=[\n        AccuracyCallback(num_classes=2),\n        OptimizerCallback(accumulation_steps=ACCUMULATION_STEPS),\n        WandbLogger(name=\"Name\", project=\"sentiment-analysis\"),\n    ],\n    fp16=FP_16,\n    logdir=LOG_DIR,\n    num_epochs=NUM_EPOCHS,\n    verbose=True\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"![](https://i.ibb.co/9wxK0Zz/Val-Metric.png)","metadata":{}},{"cell_type":"markdown","source":"After two epochs, we’ll able to reach 96.22% accuracy, which is on 6% higher than logistic regression.\n\nTo improve our result even more, we can continue fine-tuning with frozen encoder.\n\n\n### Test","metadata":{"trusted":true}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\ndef prediction(model, sentence: str, max_len: int = 512, device = 'cpu'):\n    x_encoded = tokenizer.encode_plus(sentence, add_special_tokens=True, pad_to_max_length=True, max_length=max_len, return_tensors=\"pt\",).to(device)\n    logits = model(x_encoded['input_ids'], x_encoded['attention_mask'])\n    probabilities = F.softmax(logits.detach(), dim=1)\n    output = probabilities.max(axis=1)\n    print(sentence)\n    print(f\"Class: {['Negative' if output.indices[0] == 0 else 'Positive'][0]}, Probability: {output.values[0]:.4f}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction(plain_model, df_valid['sentences'].values[20])","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}